\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

% \cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifcvprfinal\pagestyle{empty}\fi
\begin{document}

%%%%%%%%% TITLE
\title{3D Reconstruction from Multi-View Stereo:\\ From Implementation to Oculus Virtual Reality}

\author{Andrew Moran\\
  MIT, \textit{Class of 2014}\\
  {\tt\small andrewmo@mit.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Ben Eysenbach\\
MIT, \textit{Class of 2017}\\
{\tt\small bce@mit.edu}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
   Multi-View Stereo reconstructs a 3D model from a set of images. Each image is a projection of a 3D model onto the camera plane ($\mathbb{R}^3 \rightarrow \mathbb{R}^2$), which inherently results in a loss of information. With enough images taken from a variety of perspectives, a reasonable model of the original scene can be reconstructed. These reconstructions usually begin by determining where each image was taken from. Once the cameras are calibrated, a dense point cloud can be generated. A mesh can be fit over the point cloud to represent structures in the original scene. This entire process can be visualized through an Oculus Rift.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
Most current approaches to Multi-View Stereo can be broken down into three steps: feature matching, camera calibration, and dense reconstruction. In pipelines which result in a point cloud, surface reconstruction is applied as a final step.
%-------------------------------------------------------------------------
\subsection{Feature Matching}

The first step in most Multi-View Stereo pipelines is finding correspondence points between images. Once we know these points, we can determine the relative position of the cameras which took the images.

First, we select features of interest in each image. There exist numerous algorithms for selecting these points (SIFT, SURF). The general idea behind most of them is to find features which are unique enough such that finding a similar feature in another image indicates with high probability that the two features corresponds to the same object in the scene.\cite{brown}

Once features have been extracted from each image, pairwise matches must be found. Matches will not exist for all features, so some criteria must be specified for when to accept a match. One such criteria is to accept a match if the two features are each the best match for the other. Another approach is to match one feature to another feature if the best alternative match is a much worse match than the best match.\cite{brown}

\subsection{Camera Calibration}

Now that we have correspondence points, we want to compute a homography relating one image to another. If we only wanted to find the orientation of one camera relative to another, we could use RANSAC to fit a homography (with the Discrete Linear Transform).\cite{ransac} However, if we only found the optimal pairwise relative positions, they probably would not be globally consistent.

Instead, we want to find the \emph{global} optimal camera positions. One approach, Bundle Adjustment, incrementally alters the positions of the cameras to as to minimize the \emph{reprojective error} of the found correspondence points with respect to the images in which they appear. This process can be seen as minimizing a series of nonlinear equations; the Levenberg Marquardt Algorithm for nonlinear least-squares is commonly used as a subroutine. At the end of this process, we have a calibration matrix for each camera, relating the pose of each camera to a global coordinate system.\cite{snavely, sba}

\subsection{Dense Reconstruction}

We can now reconstruct the scene from calibrated cameras. We want to find eventually output a scene which is \emph{photo consistent}. Common approaches to this problem include: (1) building up a scene from points whose locations are found by triangulating between images; (2) starting with a volume which encloses the region of interest, and removing \emph{voxels} which are not photoconsistent; and (3) generating stereo depth maps for pairs of images, and then fusing them together.\cite{furukawa}

\begin{figure*}[t]
  \begin{center}
    %\fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
    \includegraphics[width=\linewidth]{pipeline3.png}

  \end{center}
  \caption{Proposed Multi-View pipeline. (A) Source Images. (B) Bundler Adjustment utilizes feature matching to create a sparse point cloud. (C) Dense Reconstruction develops a more compact point cloud. (D) Surface Reconstruction fits a mesh to the points. (E) Applying colored textures on the mesh results in a realistic simulated model.}
  \label{fig:pipeline}

\end{figure*}

\subsubsection{Point Based Approaches}

Once we have calibrated cameras with a sparse reconstruction, we can search along equipolar lines to find more correspondence points. The real-world locations of these points can be found through triangulation. In Patch-based Multi-View Stereo, these points were further expanded to \emph{patches} which included a color and normal vector.\cite{furukawa}

\subsubsection{Volumetric Approaches}

Another approach to dense reconstruction is to start with a volume which encloses the region of interest, and iteratively remove small sections (\emph{voxels}) which are not photoconsistent. Constructing the initial visual hull requires segmenting the input images into foreground and background.\cite{spacecarving}

\subsubsection{Stereo Depth Approaches}

A final approach, builds off research in stereo matching. Here, we generate depth maps for all pairs of images with overlapping fields of views. Methods include SemiGlobal Matching, Graph Cuts, and Dynamic Programming.\cite{sgm,taxonomy} These depth maps can be fused to extract the structure of the scene.\cite{fuse}


\subsection{Surface Reconstruction}
We next want to reconstruct the surface from a finite set of scattered points.  This can be viewed as an optimization problem in which the overall goal is to minimize a global energy function. This function often enforces a smoothness constraint and penalizes the distance between points and the mesh.\cite{mesh_opt}  Two common approaches to solve this problem include (1) interpolating the points with computational geometry and (2) constructing implicit functions to fit the data.

\subsubsection{ Geometric Estimation }
In this approach, the point cloud is partitioned into sections and geometric estimations are calculated at each point. For example, each point can be treated as a tangent plane and neighboring points are then projected onto this plane, giving an estimation of the surface point.\cite{surface_review, hoppe1992surface}  This utilizes methods such as Delaunay triangles, $\alpha$-shapes. \cite{surface_review, poisson} 

\subsubsection{ Function Fitting}
A more rigorous approach is to fit implicit (inside-outside) functions onto the point cloud.  This can be based on signed distance or centered radial basis functions (RBFs).\cite{poisson}  Improvements can be made to handle irregularities and outliers with the use of Moving Least Squares (MLS).\cite{szeliski2010computer}  Finding a continuous function in which the points approximately lie on the zero set determines the smoothed boundary for the mesh.  One way this can be completed is by the Marching Cubes Algorithm.\cite{hoppe1992surface}

As an example, \textit{Poisson Surface Reconstruction} utilizes the function fitting approach.  An inside-outside function is defined by gradients determined from the point normals.\cite{poisson}  In general, when undergoing surface reconstruction, it is important to ensure photoconsistencey is maintained. 

% Mesh fitting
% Poisson Surface reconstruction
% Iterative Snapping [Furukawa]
% Marching Squares/Tetrahedrons
% Voronoi

\section{Our Approach}

We will develop a pipeline which uses point-based methods to construct a densely reconstructed point cloud. From there, we will analyze various mesh-fitting surface techniques.  We plan to compare the results quantitatively evaluate them qualitatively, using the Oculus Rift. Figure \ref{fig:pipeline} summarizes the overall reconstruction process.

\subsection{Visualization}
With a 3D reconstruction, it makes sense to try to view it in three dimensions. We do this using the Oculus Rift, a head-mounted stereoscopic display. We will render the scene in a game engine, which will allow users to move around the scene.\cite{unity}

\subsection{Conclusion}
There are many applications and approaches to Multi-View Stereo. We propose a pipeline which transforms a set of images into a model of the scene.  Additionally, we propose to visualize our results using an Oculus Rift, which will shed light on the reconstruction process.

{\small
  \bibliographystyle{ieee}
  \bibliography{egbib}
}

\end{document}
