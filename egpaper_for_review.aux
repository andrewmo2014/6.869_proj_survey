\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{brown}
\citation{brown}
\citation{ransac}
\citation{snavely}
\citation{sba}
\citation{furukawa}
\citation{furukawa}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}\hskip -1em.\nobreakspace  {}Feature Matching}{1}{subsection.1.1}}
\@writefile{brf}{\backcite{brown}{{1}{1.1}{subsection.1.1}}}
\@writefile{brf}{\backcite{brown}{{1}{1.1}{subsection.1.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}\hskip -1em.\nobreakspace  {}Camera Calibration}{1}{subsection.1.2}}
\@writefile{brf}{\backcite{ransac}{{1}{1.2}{subsection.1.2}}}
\@writefile{brf}{\backcite{snavely, sba}{{1}{1.2}{subsection.1.2}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}\hskip -1em.\nobreakspace  {}Dense Reconstruction}{1}{subsection.1.3}}
\@writefile{brf}{\backcite{furukawa}{{1}{1.3}{subsection.1.3}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Point Based Approaches}{1}{subsubsection.1.3.1}}
\citation{spacecarving}
\citation{sgm}
\citation{taxonomy}
\citation{fuse}
\citation{middlebury}
\citation{middlebury}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Proposed Multi-View pipeline. (A) Source Images with known camera parameters. (B) Bundler Adjustment that utilizes feature matching to create a sparse point cloud. (C) Dense Recontruction that performs clustering to develop a more compact point cloud. (D) Surface Reconstruction adds a mesh to the points. (E) Applying colored textures on the mesh results in a realistic simulated model.}}{2}{figure.1}}
\newlabel{fig:short}{{1}{2}{Proposed Multi-View pipeline. (A) Source Images with known camera parameters. (B) Bundler Adjustment that utilizes feature matching to create a sparse point cloud. (C) Dense Recontruction that performs clustering to develop a more compact point cloud. (D) Surface Reconstruction adds a mesh to the points. (E) Applying colored textures on the mesh results in a realistic simulated model}{figure.1}{}}
\@writefile{brf}{\backcite{furukawa}{{2}{1.3.1}{subsubsection.1.3.1}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}Volumetric Approaches}{2}{subsubsection.1.3.2}}
\@writefile{brf}{\backcite{spacecarving}{{2}{1.3.2}{subsubsection.1.3.2}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}Stereo Depth Approaches}{2}{subsubsection.1.3.3}}
\@writefile{brf}{\backcite{sgm,taxonomy}{{2}{1.3.3}{subsubsection.1.3.3}}}
\@writefile{brf}{\backcite{fuse}{{2}{1.3.3}{subsubsection.1.3.3}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}\hskip -1em.\nobreakspace  {}Surface Reconstruction}{2}{subsection.1.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Our Approach}{2}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Surface Reconstruction}{2}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}Combinatorial Structures}{2}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.\nobreakspace  {}Implicit Functions}{2}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}\hskip -1em.\nobreakspace  {}Other Methods}{2}{subsection.3.3}}
\bibstyle{ieee}
\bibdata{egbib}
\bibcite{brown}{1}
\bibcite{ransac}{2}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Proposed Multi-View pre-processing and visualization pipeline, run on the Temple dataset.\cite  {middlebury} After extracting features and camera calibration parameters from imported source images, point cloud reconstructions can be created from robust computer vision packages such as Bundler and CMVS/PMVS. As a result, 3D editing software tools such as MeshLab and Blender can assist in further configuration and production of detailed meshes/textures. These can be visualized in the Unity3D game engine, which supports Oculus Rift OVR integration.}}{3}{figure.2}}
\@writefile{brf}{\backcite{middlebury}{{3}{2}{figure.2}}}
\newlabel{fig:short}{{2}{3}{Proposed Multi-View pre-processing and visualization pipeline, run on the Temple dataset.\cite {middlebury} After extracting features and camera calibration parameters from imported source images, point cloud reconstructions can be created from robust computer vision packages such as Bundler and CMVS/PMVS. As a result, 3D editing software tools such as MeshLab and Blender can assist in further configuration and production of detailed meshes/textures. These can be visualized in the Unity3D game engine, which supports Oculus Rift OVR integration}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Our Approach}{3}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Proposed Pipeline}{3}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Visualization}{3}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}\hskip -1em.\nobreakspace  {}Conclusion/Motivation}{3}{subsection.4.3}}
\bibcite{fuse}{3}
\bibcite{furukawa}{4}
\bibcite{sgm}{5}
\bibcite{spacecarving}{6}
\bibcite{sba}{7}
\bibcite{taxonomy}{8}
\bibcite{middlebury}{9}
\bibcite{snavely}{10}
